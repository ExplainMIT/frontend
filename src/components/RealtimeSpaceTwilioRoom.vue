<template>
  <div>
    <!-- Display videos above the shared blackboard -->
    <portal to="destination">
      <div class="d-flex">
        <div id="local-video"> 

        </div>
        <div id="remote-video-div"> 

        </div>
      </div>
    </portal>

    <div id="remote-audio-div"> 

    </div>

    <!-- Display current user's connection state and options -->
    <portal to="destination2">
      <p v-if="!twilioInitialized" class="accent--text">
        Joining room...
      </p>
      <template v-else>
        <p v-if="isDeafened" class="yellow--text mt-1">
          Deafened
        </p>
        <p v-else class="green--text mt-1">
          Connected
        </p>

        <v-row class="d-flex" justify="space-around">

          <v-btn v-if="!hasSharedAudio" 
            @click="shareAudioTrack()" 
            :loading="isTryingToEnableMic" 
            :class="['ma-2', 'filled', 'black--text']" tile color="white"
          >
            <v-icon left>mdi-microphone-off</v-icon> 
            Mute
          </v-btn>

          <v-btn v-else @click="$store.commit('SET_IS_MIC_ON', !isMicOn)"
            :class="isMicOn ? ['ma-2'] : ['ma-2', 'filled', 'black--text']"
            :outlined="isMicOn" tile color="white"
          >
            <v-icon left>{{ isMicOn ? 'mdi-microphone' : 'mdi-microphone-off' }}</v-icon>
            Mute
          </v-btn>

          <!-- Deafen button -->
          <v-btn @click="$store.commit('SET_IS_DEAFENED', !isDeafened)" 
            :class="isDeafened ? ['ma-2', 'filled', 'black--text'] : ['ma-2']" 
            :outlined="!isDeafened" tile color="white"
          >
            <v-icon left>{{ isDeafened ? 'mdi-headset-off' : 'mdi-headset' }}</v-icon>
            Deafen
          </v-btn>
          <!-- Disconnect button -->
          <!-- <v-btn @click.stop.prevent="$router.push(`/class/${$route.params.class_id}/section/${$route.params.section_id}`)" fab color="red" class="white--text" depressed>
            <v-icon large>mdi-phone-hangup</v-icon>
          </v-btn> -->
        </v-row>

        <v-row class="d-flex mt-2" justify="space-around">
          <!-- Enable video -->
          <v-btn @click="$store.commit('SET_IS_CAMERA_ON', !isCameraOn)" 
            :class="isCameraOn ? ['ma-2', 'filled', 'black--text'] : ['ma-2']" 
            :outlined="!isCameraOn" tile color="white"
            :loading="isTryingToEnableCamera"
          >
            <v-icon left>{{ isCameraOn ? 'mdi-video-wireless' : 'mdi-video'}}</v-icon> 
            Show video
          </v-btn>

          <!-- Turn on screenshare -->
          <v-btn @click="isSharingScreen = !isSharingScreen" 
            :loading="isTryingToEnableScreen"
            :class="isSharingScreen ? ['ma-2', 'filled', 'black--text'] : ['ma-2']" 
            :outlined="!isSharingScreen" tile color="white"
          >
            <v-icon left>{{ isSharingScreen ? 'mdi-monitor-star' : 'mdi-monitor' }} </v-icon> 
            Share screen
          </v-btn>
        </v-row>
      </template>
    </portal>

    <portal v-if="allClients" to="current-room-participants">
      <div v-for="client in allClients"
        :key="client.id" 
        :class="['d-flex', 'text--secondary', 'mt-5', 'pl-5', `${dominantParticipantSessionID === client.sessionID ? 'font-weight-black' : '' }`]"
        style="font-size: 1em"
      >
        {{ client.firstName + " " + client.lastName }}

        <v-spacer/>

        <v-icon v-if="allClientAudioStatuses.hasOwnProperty(client.sessionID)" class="mr-5">
          {{ allClientAudioStatuses[client.sessionID] ? 'mdi-microphone' : 'mdi-microphone-off' }}
        </v-icon>
      </div>
    </portal>

    <!-- Helps user fix audio issues if an error shows up -->
    <v-dialog persistent max-width="600px" v-model="isShowingErrorPopup"> 
      <v-card>
        <v-card-title>
          Couldn't connect to audio 
        </v-card-title>
        
        <v-card-text>
          <h3>Why audio isn't working</h3>
          <p>{{ whyItFailed }}</p>
          
          <h3>How to fix it</h3>
          <p>{{ howToFix }}</p>
        </v-card-text>
        <v-card-actions>
          <v-spacer/>
          <v-btn @click="isShowingErrorPopup = false" text color="secondary">
            GOT IT
          </v-btn>
        </v-card-actions>
      </v-card> 
    </v-dialog> 
  </div>
</template>

<script>
/**
 * A track is a stream of bytes that contain the data generated by a multimedia source such as a microphone or a camera.
 * Each track is wrapped by a publication.
 * 
 * For details on emitted events,
 * @see https://www.twilio.com/docs/video/migrating-1x-2x#whats-changed
 * @see screencapture https://www.twilio.com/docs/video/screen-capture-chrome
 * @see https://www.twilio.com/docs/video
 * @see API https://www.twilio.com/docs/video/tutorials/understanding-video-rooms-apis
 * @see BestPractices https://www.twilio.com/docs/video/build-js-video-application-recommendations-and-best-practices
 */
import db from "@/database.js";
import DatabaseHelpersMixin from "@/mixins/DatabaseHelpersMixin.js";
import Twilio from "twilio-video";
import { twilioCreds } from "@/twiliocreds.js";
import { mapState } from "vuex";
import Vue from "vue";

export default {
  props: {
    roomID: {
      type: String,
      required: true
    }
  },
  mixins: [
    DatabaseHelpersMixin
  ],
  data () {
    return {
      roomDoc: null,

      firebaseUnsubscribeFuncs: [],
      
      isShowingErrorPopup: false,
      whyItFailed: "",
      howToFix: "",
      
      twilioRoom: null,
      twilioInitialized: false,
      
      hasSharedAudio: false,
      isTryingToEnableMic: false,
      isTryingToEnableCamera: false,
      isTryingToEnableScreen: false,

      isSharingScreen: false,

      cameraTrack: null,
      micTrack: null,
      screenTrack: null,

      micPublication: null,
      cameraPublication: null,
      screenPublication: null,
      
      // Contains connected participants with a published audio stream
      // Maps sessionID to the remote participants isMicOn value
      participantAudioStatus: {},
      
      // The remote participant sessionID with the loudest audioTrack
      // null means either there are no other participants, or no participants are speaking
      dominantParticipantSessionID: null
    };
  },
  computed: {
    ...mapState([
      "user",
      "session",
      "isMicOn",
      "isCameraOn",
      "isDeafened"
    ]),
    allClients () {
      if (!this.$store.state.roomIDtoParticipants) {
        return; 
      }
      return this.$store.state.roomIDtoParticipants[this.roomID]; 
    },
    sessionID () { 
      return this.session.currentID; 
    },
    allClientAudioStatuses () {
      return {
        [this.sessionID]: this.isMicOn,
        ...this.participantAudioStatus
      };  
    }
  },
  async created () {
    if (!this.isTwilioSupportedByBrowser()) {
      return; 
    }
    try {
      this.twilioRoom = await Twilio.connect(this.getAccessToken(), { 
        name: this.roomID,
        audio: false, // should be able to just connect without anything
        dominantSpeaker: true
        // video: { width: 640 }
      }); 
    } catch (error) {
      this.tellUserHowToFixError(error);
      return;
    }
    
    // persist the camera/mic settings from the previous room 
    if (this.isMicOn) this.shareAudioTrack(); 
    if (this.isCameraOn) this.shareCameraTrack(); 
    if (this.isDeafened) this.disconnectFromAudio();
    
    // others => me
    this.twilioRoom.participants.forEach(
      participant => this.handleHisOrHerTracks(participant)
    );
    
    this.twilioRoom.on("participantConnected", 
      participant => this.handleHisOrHerTracks(participant)
    );

    this.twilioRoom.on("participantDisconnected", participant => {
      Vue.delete(this.participantAudioStatus, participant.identity);
      this.removeHisOrHerSharedTracks(participant);
    });

    this.twilioRoom.on("dominantSpeakerChanged", participant => {
      if (!participant) console.log("participant is null!"); 
      this.dominantParticipantSessionID = participant ? participant.identity : null;
    });

    // me => others
    window.addEventListener("beforeunload", this.twilioRoom.disconnect);
    window.addEventListener("pagehide", this.twilioRoom.disconnect);
    
    // to detect the mute all TODO: refactor
    this.$_listenToDoc(
      db.doc(`classes/${this.$route.params.class_id}/rooms/${this.roomID}`),
      this, 
      "roomDoc"
    ).then(unsubscribe => this.firebaseUnsubscribeFuncs.push(unsubscribe));

    this.twilioInitialized = true;
  },
  beforeDestroy () {
    // remove the "mute everyone" listener
    for (const unsubscribe of this.firebaseUnsubscribeFuncs) {
      unsubscribe();
    }

    // disable camera, mic, etc. to turn off the lights
    if (this.cameraTrack) this.cameraTrack.stop();
    if (this.micTrack) this.micTrack.stop();
    if (this.screenTrack) this.screenTrack.stop(); 

    if (this.twilioRoom) {
      // disable mic
      this.twilioRoom.localParticipant.audioTracks.forEach(audioTrack => {
        publication => publication.track.stop(); 
      }); 

      // stop displaying other people's tracks
      this.twilioRoom.participants.forEach(otherPerson => {
        this.removeHisOrHerSharedTracks(otherPerson);
      });

      // notify other people that I disconnected
      this.twilioRoom.disconnect();
      window.removeEventListener("beforeunload", this.twilioRoom.disconnect);
      window.removeEventListener("pagehide", this.twilioRoom.disconnect);
    }
  },
  watch: {
    // Detect mute all
    roomDoc (newVal, oldVal) {
      // Check if we need to enable trigger a muteAll
      if (oldVal !== null && newVal.muteAllCounter != oldVal.muteAllCounter) {
        if (this.isMicOn) {
          this.$store.commit("SET_IS_MIC_ON", false);
          this.$root.$emit("show-snackbar", "You were muted by an admin.");
        }
      }
    },
    isMicOn (newValue) {
      const { audioTracks } = this.twilioRoom.localParticipant; 
      if (newValue) {
        audioTracks.forEach(publication => publication.track.enable());
      } else {
        audioTracks.forEach(publication => publication.track.disable());
      }
    },
    async isCameraOn (newValue) {
      if (newValue) {
        this.shareCameraTrack(); 
      } else {
        this.cameraTrack.stop(); // turn off camera lights from my device
        this.cameraPublication.unpublish(); // update other people so they can remove my screen
        this.unmountTrack(this.cameraPublication.track); // remove my local screenshare UI
      }
    },
    async isSharingScreen (newVal) {
      if (newVal) {
        try {
          this.isTryingToEnableScreen = true; 
          const stream = await navigator.mediaDevices.getDisplayMedia({ 
            audio: false // I think audio: false prevents MacOS Safari from throwing a"type error"
          });
          this.screenTrack = new Twilio.LocalVideoTrack(stream.getTracks()[0]); 
          this.screenPublication = await this.twilioRoom.localParticipant.publishTrack(this.screenTrack);
          this.displayLocalVisualFeedback(this.screenTrack);
        } catch (error) {
          this.tellUserHowToFixError(error);
          this.isSharingScreen = false; 
        } finally {
          this.isTryingToEnableScreen = false; 
        }
      } 
      else {
        this.screenTrack.stop(); // stop the "explain.mit.edu is sharing your screen"
        this.screenPublication.unpublish(); 
        this.unmountTrack(this.screenPublication.track); // stop local visual feedback 
      }
    },
    isDeafened (newVal) {
      if (newVal) {
        this.disconnectFromAudio(); 
      } else {
        // // unmute myself
        // this.$store.commit("SET_IS_MIC_ON", true);
        // this.shareAudioTrack(); 
        
        // unsilence other people 
        this.twilioRoom.participants.forEach(person => {
          person.audioTracks.forEach(publication => {
            if (publication.isSubscribed) {
              this.mountAudioTrack(publication.track);
            }
          });
        }); 
      }
    }
  },
  methods: {
    async disconnectFromAudio () {
      if (this.hasSharedAudio) {
        this.micPublication.unpublish(); 
        this.micPublication.track.stop();

        // update component state
        // doesn't matter if the user was muted or not, now his/her mic is off
        this.$store.commit("SET_IS_MIC_ON", false); 
        this.hasSharedAudio = false; 
      }

      // silence other people
      this.twilioRoom.participants.forEach(person => {
        person.audioTracks.forEach(publication => this.unmountTrack(publication.track));
      }); 
    },
    async shareCameraTrack () {
      this.isTryingToEnableCamera = true; 
      this.cameraTrack = await Twilio.createLocalVideoTrack();
      this.cameraTrack.enable();
      this.cameraPublication = await this.twilioRoom.localParticipant.publishTrack(this.cameraTrack);
      await this.displayLocalVisualFeedback(this.cameraTrack);
      this.isTryingToEnableCamera = false; 
    },
    async shareAudioTrack () {
      // if the user connects to audio, also re-enable sound, otherwise the user
      // could be talking without being aware that others can hear him
      this.$store.commit("SET_IS_DEAFENED", false);
    
      this.isTryingToEnableMic = true; 
      this.micTrack = await Twilio.createLocalAudioTrack();
      this.micTrack.enable();
      this.micPublication = await this.twilioRoom.localParticipant.publishTrack(this.micTrack);       
      this.isTryingToEnableMic = false; 
      this.$store.commit("SET_IS_MIC_ON", true);
      this.hasSharedAudio = true;
    },
    handleHisOrHerTracks (participant) {
      // first initialize their status as muted
      // then if they shared tracks, then their audio status will be updated to true
      Vue.set(
        this.participantAudioStatus,
        participant.identity,
        false
      );
      // mount streams they're currently sharing
      participant.tracks.forEach(publication => {
        if (publication.isSubscribed) {
          this.handleNewlyReceivedTrack(publication.track, participant);
        }
      });
      // mount/unmount streams that they'll share/unshare in the future 
      // "trackSubscribed" is fired on my laptop whenever someone else publishes a track
      participant.on("trackSubscribed", track => {
        this.handleNewlyReceivedTrack(track, participant);
      });
      participant.on("trackUnsubscribed", this.unmountTrack);
    },
    handleNewlyReceivedTrack (track, participant) {
      if (track.kind === "video") {        
        this.mountVideoTrack(track);
      } 
      else if (track.kind === "audio") {
        if (!this.isDeafened) {
          this.mountAudioTrack(track);
        }
        // update mic statuses for displaying on the UI
        const updateAudioStatuses = () => Vue.set(
          this.participantAudioStatus,
          participant.identity,
          track.isEnabled
        );
        updateAudioStatuses();
        track.on("disabled", updateAudioStatuses);
        track.on("enabled", updateAudioStatuses);
      } 
    },
    displayLocalVisualFeedback (visualTrack) {
      const htmlVideoElement = visualTrack.attach();
      htmlVideoElement.height = 150; 
      htmlVideoElement.width = 210;
      document.getElementById("local-video").appendChild(htmlVideoElement);
    },
    /**
     * The functions below takes in a track (audio or video)
     * and makes it observable or not observable to the user.
     * 
     * track.attach() = 
     *   <audio autoplay></audio>
     *   <video autoplay playsinline></video>
     *   ...etc.
     * 
     * TODO: Add support for mounting video tracks
     */
    async mountAudioTrack (audioTrack) {
      const audioElement = audioTrack.attach();
      // if (this.audioDevices && this.audioDevices.output) {
      //   await audioElement.setSinkId(this.audioDevices.output);
      // }
      document.getElementById("remote-audio-div").appendChild(audioElement);
    },
    async mountVideoTrack (videoTrack) {
      const videoElement = videoTrack.attach();
      // make smaller
      videoElement.height = 150;
      videoElement.width = 210;
      videoElement.controls = true; // allow the user to fullscreen
      document.getElementById("remote-video-div").appendChild(videoElement);
    },
    removeHisOrHerSharedTracks (participant) {
      for (const publication in participant.tracks) {
        if (publication.track) {
          this.unmountTrack(publication.track);
        }
      }
    },
    unmountTrack (track) {
      const htmlElements = track.detach();
      for (const element of htmlElements) {
        element.remove();
      }
    },
    /**
     * Creates an "access token" that is required to join a Twilio room.
     * @see https://www.twilio.com/docs/video/tutorials/user-identity-access-tokens
     */
    getAccessToken () {
      const AccessToken = require('twilio').jwt.AccessToken;
      const VideoGrant = AccessToken.VideoGrant;
      const token = new AccessToken(
        twilioCreds.ACCOUNT_SID,
        twilioCreds.API_KEY_SID,
        twilioCreds.API_KEY_SECRET
      );
      token.identity = this.sessionID;
      const videoGrant = new VideoGrant();
      token.addGrant(videoGrant);
      return token.toJwt();
    },
    isTwilioSupportedByBrowser () {
      if (!Twilio.isSupported) {
        this.isShowingErrorPopup = true; 
        this.whyItFailed = "Your browser/device combination does not support audio/video/screensharing."; 
        this.howToFix = `
          For iPads, use iOS Safari. 
          For MacBooks, use MacOS Chrome, Firefox or Safari. 
          For Windows, use Chrome or Firefox. 
          For Linux, use Chrome or Firefox. 
        `;
        return false; 
      }
      return true; 
    },
    tellUserHowToFixError (error) {
      this.isShowingErrorPopup = true; 

      if (error.name === "NotFoundError") {
        this.whyItFailed = `Your laptop or iPad's audio device is currently disabled in this browser.`;
        this.howToFix = `Enable your audio device for the browser in the system settings.`;
      } else if (error.name === "NotAllowedError") {
        this.whyItFailed = `At some point, you dismissed or denied the popup that asked for access to your microphone`;
        this.howToFix = `
          Try to find the settings for your microphone, and click enable. The below steps usually works:
            1. Find a button (a lock icon or an "i" button or something else) near the left of "https://explain.mit.edu/...." 
            2. Find the settings somewhere for the audio microphone and switch to "allow" 
            3. Reload the entire website. 
          If that doesn't work, try switching browsers e.g. flip between Safari and Chrome. 
          If that still doesn't work, you can Facetime me +886 965 602 567. 
        `;
      } else {
        this.whyItFailed = `Failed to acquire audio media because: ${error.message}`;
        this.howToFix = ""; 
      }
    }
  }
}
</script>
<template>
  <div>
    <!-- Display videos above the shared blackboard -->
    <portal to="destination">
      <div class="d-flex">
        <div id="local-video"> 

        </div>
        <div id="remote-video-div"> 

        </div>
      </div>
    </portal>

    <div id="remote-audio-div"> 

    </div>

    <!-- Display current user's connection state and options -->
    <portal to="destination2">
      <p v-if="!twilioInitialized" class="accent--text">
        Connecting audio...
      </p>
      <template v-else>
        <p class="green--text mt-1">
          Connected 
        </p>
        <v-row class="d-flex" justify="space-around">
          <!-- Mute button -->
          <v-btn @click="isMicEnabled = !isMicEnabled" fab color="grey" class="white--text" depressed>
            <v-icon large>{{ isMicEnabled ? 'mdi-microphone' : 'mdi-microphone-off'  }}</v-icon>
          </v-btn>
          
          <!-- Deafen button -->
          <v-btn @click="isDeafened = !isDeafened" fab color="grey" class="white--text" depressed>
            <v-icon large>{{ isDeafened ? 'mdi-headset-off' : 'mdi-headset' }}</v-icon>
          </v-btn>

          <!-- Disconnect button -->
          <v-btn @click.stop.prevent="$router.push(`/class/${$route.params.class_id}/section/${$route.params.section_id}`)" fab color="red" class="white--text" depressed>
            <v-icon large>mdi-phone-hangup</v-icon>
          </v-btn>
        </v-row>

        <v-row class="d-flex mt-2" justify="space-around">
          <!-- 'mdi-video' -->
          <v-btn @click="isCameraEnabled = !isCameraEnabled" class="ma-2" large tile outlined color="white">
            <v-icon left>mdi-video</v-icon> Video
          </v-btn>

          <!-- mdi-monitor-speaker-off -->
          <v-btn @click="isSharingScreen = !isSharingScreen" class="ma-2" tile outlined large color="white">
            <v-icon left>mdi-monitor</v-icon> Screen
          </v-btn>
        </v-row>
      </template>
    </portal>

    <portal to="destination3">
      <template v-if="allClients">
        <div v-for="client in allClients"
          :key="client.id" 
          :class="['d-flex', `${dominantParticipantSessionID === client.sessionID ? 'font-weight-black' : '' }`]"
          style="font-size: 0.8em"
        >
          {{ client.firstName + " " + client.lastName }}

          <v-spacer/>

          <v-icon v-if="allClientAudioStatuses.hasOwnProperty(client.sessionID)" small>
            {{ allClientAudioStatuses[client.sessionID] ? 'mdi-microphone' : 'mdi-microphone-off' }}
          </v-icon>
        </div>
      </template>
    </portal>

    <!-- Helps user fix audio issues if an error shows up -->
    <v-dialog persistent max-width="600px" v-model="isShowingErrorPopup"> 
      <v-card>
        <v-card-title>
          Couldn't connect to audio 
        </v-card-title>
        <v-card-text>
          <h3>Why audio isn't working</h3>
          <p>{{ whyItFailed }}</p>
          <h3>How to fix it</h3>
          <p>{{ howToFix }}</p>
        </v-card-text>
        <v-card-actions>
          <v-spacer/>
          <v-btn @click="isShowingErrorPopup = false" text color="secondary">
            GOT IT
          </v-btn>
        </v-card-actions>
      </v-card> 
    </v-dialog> 
  </div>
</template>

<script>
/**
 * A track is a stream of bytes that contain the data generated by a multimedia source such as a microphone or a camera.
 * Each track is wrapped by a publication.
 * 
 * For details on emitted events,
 * @see https://www.twilio.com/docs/video/migrating-1x-2x#whats-changed
 * @see screencapture https://www.twilio.com/docs/video/screen-capture-chrome
 * @see https://www.twilio.com/docs/video
 * @see API https://www.twilio.com/docs/video/tutorials/understanding-video-rooms-apis
 * @see BestPractices https://www.twilio.com/docs/video/build-js-video-application-recommendations-and-best-practices
 */
import db from "@/database.js";
import DatabaseHelpersMixin from "@/mixins/DatabaseHelpersMixin.js";
import Twilio from "twilio-video";
import { twilioCreds } from "@/twiliocreds.js";
import { mapState } from "vuex";
import Vue from "vue";

export default {
  props: {
    roomID: {
      type: String,
      required: true
    }
  },
  mixins: [
    DatabaseHelpersMixin
  ],
  data () {
    return {
      allClients: null,

      roomDoc: null,

      firebaseUnsubscribeFuncs: [],
      
      isShowingErrorPopup: false,
      whyItFailed: "",
      howToFix: "",
      
      twilioRoom: null,
      twilioInitialized: false,
      
      isMicEnabled: true,
      isCameraEnabled: false,
      isDeafened: false,
      isSharingScreen: false,

      cameraTrack: null,
      micTrack: null,
      screenTrack: null,
      
      // Contains connected participants with a published audio stream
      // Maps sessionID to the remote participants isMicEnabled value
      participantAudioStatus: {},
      
      // The remote participant sessionID with the loudest audioTrack
      // null means either there are no other participants, or no participants are speaking
      dominantParticipantSessionID: null
    };
  },
  computed: {
    ...mapState([
      "user",
      "session"
    ]),
    sessionID () { 
      return this.session.currentID; 
    },
    allClientAudioStatuses () {
      return {
        [this.sessionID]: this.isMicEnabled,
        ...this.participantAudioStatus
      };  
    }
  },
  watch: {
    allClients () {
      console.log("allClients changed =", this.allClients); 
    }
  },
  async created () {
    // quickfix for the missing prop this.allClients
    const { class_id } = this.$route.params; 
    this.firebaseUnsubscribeFuncs.push(
      this.$_bindVarToDB({
        component: this,
        varName: "allClients",
        dbRef: db.collection(`/classes/${class_id}/participants`)
          .where("currentRoom", "==", this.$route.params.room_id)
      })
    ); 
    console.log("binding allClients to the ref");

    if (!this.isTwilioSupportedByBrowser()) {
      return; 
    }
    try {
      this.twilioRoom = await Twilio.connect(this.getAccessToken(), { 
        name: this.roomID,
        audio: true, // should be able to just connect without anything
        dominantSpeaker: true
        // video: { width: 640 }
      }); 
    } catch (error) {
      this.tellUserHowToFixError(error);
      return;
    }
    
    // others => me
    this.twilioRoom.participants.forEach(
      participant => this.handleHisOrHerTracks(participant)
    );
    
    this.twilioRoom.on("participantConnected", 
      participant => this.handleHisOrHerTracks(participant)
    );

    this.twilioRoom.on("participantDisconnected", participant => {
      Vue.delete(this.participantAudioStatus, participant.identity);
      this.removeHisOrHerSharedTracks(participant);
    });

    this.twilioRoom.on("dominantSpeakerChanged", participant => {
      if (!participant) console.log("participant is null!"); 
      this.dominantParticipantSessionID = participant ? participant.identity : null;
    });

    // me => others
    window.addEventListener("beforeunload", this.twilioRoom.disconnect);
    window.addEventListener("pagehide", this.twilioRoom.disconnect);
    
    // to detect the mute all TODO: refactor
    this.$_listenToDoc(
      db.doc(`classes/${this.$route.params.class_id}/rooms/${this.roomID}`),
      this, 
      "roomDoc"
    ).then(unsubscribe => this.firebaseUnsubscribeFuncs.push(unsubscribe));

    this.twilioInitialized = true;
  },
  beforeDestroy () {
    // remove the "mute everyone" listener
    for (const unsubscribe of this.firebaseUnsubscribeFuncs) {
      unsubscribe();
    }

    // disable camera, mic, etc. to turn off the lights
    if (this.cameraTrack) this.cameraTrack.stop();

    // if (this.micTrack) this.micTrack.stop();
    if (this.screenTrack) this.screenTrack.stop(); 

    if (this.twilioRoom) {
      // disable mic
      this.twilioRoom.localParticipant.audioTracks.forEach(audioTrack => {
        publication => publication.track.stop(); 
      }); 
      
      // stop displaying other people's tracks
      this.twilioRoom.participants.forEach(otherPerson => {
        this.removeHisOrHerSharedTracks(otherPerson);
      });

      // notify other people that I disconnected
      this.twilioRoom.disconnect();
      window.removeEventListener("beforeunload", this.twilioRoom.disconnect);
      window.removeEventListener("pagehide", this.twilioRoom.disconnect);
    }
  },
  watch: {
    // Detect mute all
    roomDoc (newVal, oldVal) {
      // Check if we need to enable trigger a muteAll
      if (oldVal !== null && newVal.muteAllCounter != oldVal.muteAllCounter) {
        if (this.isMicEnabled) {
          this.isMicEnabled = false;
          this.$root.$emit("show-snackbar", "You were muted by an admin.");
        }
      }
    },
    isMicEnabled (newValue) {
      if (!this.twilioRoom) return;
      if (newValue) {
        this.twilioRoom.localParticipant.audioTracks.forEach(
          publication => publication.track.enable()
        );
      } else {
        this.twilioRoom.localParticipant.audioTracks.forEach(
          publication => publication.track.disable()
        );
      }
    },
    async isCameraEnabled (newValue) {
      if (newValue) {
        this.cameraTrack = await Twilio.createLocalVideoTrack();
        this.cameraTrack.enable();
        this.shareMyVisualTrackWithEveryone(this.cameraTrack);
      } 
      else {
        this.stopSharingMyVisualTracks();
      }
    },
    async isSharingScreen (newValue) {
      if (newValue) {
        try {
          // I think audio: false prevents MacOS Safari from throwing a"type error"
          const myScreenStream = await navigator.mediaDevices.getDisplayMedia({ audio: false });
          this.shareMyVisualTrackWithEveryone(
            new Twilio.LocalVideoTrack(myScreenStream.getTracks()[0])
          );
        } catch (error) {
          this.tellUserHowToFixError(error);
        }
      } 
      else {
        this.stopSharingMyVisualTracks(); 
      }
    },
    isDeafened (isDeafened) {
      if (isDeafened) {
        // mute myself 
        this.isMicEnabled = false; 

        // silence other people
        this.twilioRoom.participants.forEach(person => {
          person.audioTracks.forEach(publication => this.unmountTrack(publication.track));
        }); 
      } 
      else {
        // unmute myself
        this.isMicEnabled = true; 
        
        // unsilence other people 
        this.twilioRoom.participants.forEach(person => {
          person.audioTracks.forEach(publication => {
            if (publication.isSubscribed) {
              this.mountAudioTrack(publication.track);
            }
          });
        }); 
      }
    }
  },
  methods: {
    handleHisOrHerTracks (participant) {
      // mount streams they're currently sharing
      participant.tracks.forEach(publication => {
        if (publication.isSubscribed) {
          this.handleNewlyReceivedTrack(publication.track, participant);
        }
      });
      // mount/unmount streams that they'll share/unshare in the future 
      // "trackSubscribed" is fired on my laptop whenever someone else publishes a track
      participant.on("trackSubscribed", track => {
        this.handleNewlyReceivedTrack(track, participant);
      });
      participant.on("trackUnsubscribed", this.unmountTrack);
    },
    handleNewlyReceivedTrack (track, participant) {
      if (track.kind === "video") {        
        this.mountVideoTrack(track);
      } 
      else if (track.kind === "audio") {
        if (!this.isDeafened) {
          this.mountAudioTrack(track);
        }
        // update mic statuses for displaying on the UI
        const updateAudioStatuses = () => Vue.set(
          this.participantAudioStatus,
          participant.identity,
          track.isEnabled
        );
        updateAudioStatuses();
        track.on("disabled", updateAudioStatuses);
        track.on("enabled", updateAudioStatuses);
      } 
    },
    shareMyVisualTrackWithEveryone (visualTrack) {
      // publish to other people in the room
      this.twilioRoom.localParticipant.publishTrack(visualTrack);

      // display local feedback 
      const htmlVideoElement = visualTrack.attach();
      htmlVideoElement.height = 150; 
      htmlVideoElement.width = 210;
      document.getElementById("local-video").appendChild(htmlVideoElement);
    },
    stopSharingMyVisualTracks () {
      this.twilioRoom.localParticipant.videoTracks.forEach(publication => {
        // publication.track.disable(); 
        publication.unpublish();

        // hide local preview
        this.unmountTrack(publication.track); 
      });
    },
    /**
     * The functions below takes in a track (audio or video)
     * and makes it observable or not observable to the user.
     * 
     * track.attach() = 
     *   <audio autoplay></audio>
     *   <video autoplay playsinline></video>
     *   ...etc.
     * 
     * TODO: Add support for mounting video tracks
     */
    async mountAudioTrack (audioTrack) {
      const audioElement = audioTrack.attach();
      if (this.audioDevices && this.audioDevices.output) {
        await audioElement.setSinkId(this.audioDevices.output);
      }
      document.getElementById("remote-audio-div").appendChild(audioElement);
    },
    async mountVideoTrack (videoTrack) {
      const videoElement = videoTrack.attach();
      // make smaller
      videoElement.height = 150;
      videoElement.width = 210;
      videoElement.controls = true; // allow the user to fullscreen
      document.getElementById("remote-video-div").appendChild(videoElement);
    },
    removeHisOrHerSharedTracks (participant) {
      for (const publication in participant.tracks) {
        if (publication.track) {
          this.unmountTrack(publication.track);
        }
      }
    },
    unmountTrack (track) {
      const htmlElements = track.detach();
      for (const element of htmlElements) {
        element.remove();
      }
    },
    /**
     * Creates an "access token" that is required to join a Twilio room.
     * @see https://www.twilio.com/docs/video/tutorials/user-identity-access-tokens
     */
    getAccessToken () {
      const AccessToken = require('twilio').jwt.AccessToken;
      const VideoGrant = AccessToken.VideoGrant;
      const token = new AccessToken(
        twilioCreds.ACCOUNT_SID,
        twilioCreds.API_KEY_SID,
        twilioCreds.API_KEY_SECRET
      );
      token.identity = this.sessionID;
      const videoGrant = new VideoGrant();
      token.addGrant(videoGrant);
      return token.toJwt();
    },
    isTwilioSupportedByBrowser () {
      if (!Twilio.isSupported) {
        this.isShowingErrorPopup = true; 
        this.whyItFailed = "Your browser/device combination does not support audio/video/screensharing."; 
        this.howToFix = `
          For iPads, use iOS Safari. 
          For MacBooks, use MacOS Chrome, Firefox or Safari. 
          For Windows, use Chrome or Firefox. 
          For Linux, use Chrome or Firefox. 
        `;
        return false; 
      }
      return true; 
    },
    tellUserHowToFixError (error) {
      this.isShowingErrorPopup = true; 

      if (error.name === "NotFoundError") {
        this.whyItFailed = `Your laptop or iPad's audio device is currently disabled in this browser.`;
        this.howToFix = `Enable your audio device for the browser in the system settings.`;
      } else if (error.name === "NotAllowedError") {
        this.whyItFailed = `At some point, you dismissed or denied the popup that asked for access to your microphone`;
        this.howToFix = `
          Try to find the settings for your microphone, and click enable. The below steps usually works:
            1. Find a button (a lock icon or an "i" button or something else) near the left of "https://explain.mit.edu/...." 
            2. Find the settings somewhere for the audio microphone and switch to "allow" 
            3. Reload the entire website. 
          If that doesn't work, try switching browsers e.g. flip between Safari and Chrome. 
          If that still doesn't work, you can Facetime me +886 965 602 567. 
        `;
      } else {
        this.whyItFailed = `Failed to acquire audio media because: ${error.message}`;
        this.howToFix = ""; 
      }
    }
  }
}
</script>